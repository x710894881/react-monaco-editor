{"ast":null,"code":"/*---------------------------------------------------------------------------------------------\n *  Copyright (c) Artyom Shalkhakov. All rights reserved.\n *  Licensed under the MIT License. See License.txt in the project root for license information.\n *\n *  Based on the ATS/Postiats lexer by Hongwei Xi.\n *--------------------------------------------------------------------------------------------*/\n'use strict';\n\nexport var conf = {\n  comments: {\n    lineComment: '//',\n    blockComment: ['(*', '*)']\n  },\n  brackets: [['{', '}'], ['[', ']'], ['(', ')'], ['<', '>']],\n  autoClosingPairs: [{\n    open: '\"',\n    close: '\"',\n    notIn: ['string', 'comment']\n  }, {\n    open: '{',\n    close: '}',\n    notIn: ['string', 'comment']\n  }, {\n    open: '[',\n    close: ']',\n    notIn: ['string', 'comment']\n  }, {\n    open: '(',\n    close: ')',\n    notIn: ['string', 'comment']\n  }]\n};\nexport var language = {\n  tokenPostfix: '.pats',\n  // TODO: staload and dynload are followed by a special kind of string literals\n  // with {$IDENTIFER} variables, and it also may make sense to highlight\n  // the punctuation (. and / and \\) differently.\n  // Set defaultToken to invalid to see what you do not tokenize yet\n  defaultToken: 'invalid',\n  // keyword reference: https://github.com/githwxi/ATS-Postiats/blob/master/src/pats_lexing_token.dats\n  keywords: [//\n  \"abstype\", \"abst0ype\", \"absprop\", \"absview\", \"absvtype\", \"absviewtype\", \"absvt0ype\", \"absviewt0ype\", //\n  \"as\", //\n  \"and\", //\n  \"assume\", //\n  \"begin\", //\n\n  /*\n          \"case\", // CASE\n  */\n  //\n  \"classdec\", //\n  \"datasort\", //\n  \"datatype\", \"dataprop\", \"dataview\", \"datavtype\", \"dataviewtype\", //\n  \"do\", //\n  \"end\", //\n  \"extern\", \"extype\", \"extvar\", //\n  \"exception\", //\n  \"fn\", \"fnx\", \"fun\", //\n  \"prfn\", \"prfun\", //\n  \"praxi\", \"castfn\", //\n  \"if\", \"then\", \"else\", //\n  \"ifcase\", //\n  \"in\", //\n  \"infix\", \"infixl\", \"infixr\", \"prefix\", \"postfix\", //\n  \"implmnt\", \"implement\", //\n  \"primplmnt\", \"primplement\", //\n  \"import\", //\n\n  /*\n          \"lam\", // LAM\n          \"llam\", // LLAM\n          \"fix\", // FIX\n  */\n  //\n  \"let\", //\n  \"local\", //\n  \"macdef\", \"macrodef\", //\n  \"nonfix\", //\n  \"symelim\", \"symintr\", \"overload\", //\n  \"of\", \"op\", //\n  \"rec\", //\n  \"sif\", \"scase\", //\n  \"sortdef\",\n  /*\n  // HX: [sta] is now deprecated\n  */\n  \"sta\", \"stacst\", \"stadef\", \"static\",\n  /*\n          \"stavar\", // T_STAVAR\n  */\n  //\n  \"staload\", \"dynload\", //\n  \"try\", //\n  \"tkindef\", //\n\n  /*\n          \"type\", // TYPE\n  */\n  \"typedef\", \"propdef\", \"viewdef\", \"vtypedef\", \"viewtypedef\", //\n\n  /*\n          \"val\", // VAL\n  */\n  \"prval\", //\n  \"var\", \"prvar\", //\n  \"when\", \"where\", //\n\n  /*\n          \"for\", // T_FOR\n          \"while\", // T_WHILE\n  */\n  //\n  \"with\", //\n  \"withtype\", \"withprop\", \"withview\", \"withvtype\", \"withviewtype\"],\n  keywords_dlr: [\"$delay\", \"$ldelay\", //\n  \"$arrpsz\", \"$arrptrsize\", //\n  \"$d2ctype\", //\n  \"$effmask\", \"$effmask_ntm\", \"$effmask_exn\", \"$effmask_ref\", \"$effmask_wrt\", \"$effmask_all\", //\n  \"$extern\", \"$extkind\", \"$extype\", \"$extype_struct\", //\n  \"$extval\", \"$extfcall\", \"$extmcall\", //\n  \"$literal\", //\n  \"$myfilename\", \"$mylocation\", \"$myfunction\", //\n  \"$lst\", \"$lst_t\", \"$lst_vt\", \"$list\", \"$list_t\", \"$list_vt\", //\n  \"$rec\", \"$rec_t\", \"$rec_vt\", \"$record\", \"$record_t\", \"$record_vt\", //\n  \"$tup\", \"$tup_t\", \"$tup_vt\", \"$tuple\", \"$tuple_t\", \"$tuple_vt\", //\n  \"$break\", \"$continue\", //\n  \"$raise\", //\n  \"$showtype\", //\n  \"$vcopyenv_v\", \"$vcopyenv_vt\", //\n  \"$tempenver\", //\n  \"$solver_assert\", \"$solver_verify\"],\n  keywords_srp: [//\n  \"#if\", \"#ifdef\", \"#ifndef\", //\n  \"#then\", //\n  \"#elif\", \"#elifdef\", \"#elifndef\", //\n  \"#else\", \"#endif\", //\n  \"#error\", //\n  \"#prerr\", \"#print\", //\n  \"#assert\", //\n  \"#undef\", \"#define\", //\n  \"#include\", \"#require\", //\n  \"#pragma\", \"#codegen2\", \"#codegen3\"],\n  irregular_keyword_list: [\"val+\", \"val-\", \"val\", \"case+\", \"case-\", \"case\", \"addr@\", \"addr\", \"fold@\", \"free@\", \"fix@\", \"fix\", \"lam@\", \"lam\", \"llam@\", \"llam\", \"viewt@ype+\", \"viewt@ype-\", \"viewt@ype\", \"viewtype+\", \"viewtype-\", \"viewtype\", \"view+\", \"view-\", \"view@\", \"view\", \"type+\", \"type-\", \"type\", \"vtype+\", \"vtype-\", \"vtype\", \"vt@ype+\", \"vt@ype-\", \"vt@ype\", \"viewt@ype+\", \"viewt@ype-\", \"viewt@ype\", \"viewtype+\", \"viewtype-\", \"viewtype\", \"prop+\", \"prop-\", \"prop\", \"type+\", \"type-\", \"type\", \"t@ype\", \"t@ype+\", \"t@ype-\", \"abst@ype\", \"abstype\", \"absviewt@ype\", \"absvt@ype\", \"for*\", \"for\", \"while*\", \"while\"],\n  keywords_types: ['bool', 'double', 'byte', 'int', 'short', 'char', 'void', 'unit', 'long', 'float', 'string', 'strptr'],\n  // TODO: reference for this?\n  keywords_effects: [\"0\", \"fun\", \"clo\", \"prf\", \"funclo\", \"cloptr\", \"cloref\", \"ref\", \"ntm\", \"1\" // all effects\n  ],\n  operators: [\"@\", \"!\", \"|\", \"`\", \":\", \"$\", \".\", \"=\", \"#\", \"~\", //\n  \"..\", \"...\", //\n  \"=>\", // \"=<\", // T_EQLT\n  \"=<>\", \"=/=>\", \"=>>\", \"=/=>>\", //\n  \"<\", \">\", //\n  \"><\", //\n  \".<\", \">.\", //\n  \".<>.\", //\n  \"->\", //\"-<\", // T_MINUSLT\n  \"-<>\"],\n  brackets: [{\n    open: ',(',\n    close: ')',\n    token: 'delimiter.parenthesis'\n  }, {\n    open: '`(',\n    close: ')',\n    token: 'delimiter.parenthesis'\n  }, {\n    open: '%(',\n    close: ')',\n    token: 'delimiter.parenthesis'\n  }, {\n    open: '\\'(',\n    close: ')',\n    token: 'delimiter.parenthesis'\n  }, {\n    open: '\\'{',\n    close: '}',\n    token: 'delimiter.parenthesis'\n  }, {\n    open: '@(',\n    close: ')',\n    token: 'delimiter.parenthesis'\n  }, {\n    open: '@{',\n    close: '}',\n    token: 'delimiter.brace'\n  }, {\n    open: '@[',\n    close: ']',\n    token: 'delimiter.square'\n  }, {\n    open: '#[',\n    close: ']',\n    token: 'delimiter.square'\n  }, {\n    open: '{',\n    close: '}',\n    token: 'delimiter.curly'\n  }, {\n    open: '[',\n    close: ']',\n    token: 'delimiter.square'\n  }, {\n    open: '(',\n    close: ')',\n    token: 'delimiter.parenthesis'\n  }, {\n    open: '<',\n    close: '>',\n    token: 'delimiter.angle'\n  }],\n  // we include these common regular expressions\n  symbols: /[=><!~?:&|+\\-*\\/\\^%]+/,\n  IDENTFST: /[a-zA-Z_]/,\n  IDENTRST: /[a-zA-Z0-9_'$]/,\n  symbolic: /[%&+-./:=@~`^|*!$#?<>]/,\n  digit: /[0-9]/,\n  digitseq0: /@digit*/,\n  xdigit: /[0-9A-Za-z]/,\n  xdigitseq0: /@xdigit*/,\n  INTSP: /[lLuU]/,\n  FLOATSP: /[fFlL]/,\n  fexponent: /[eE][+-]?[0-9]+/,\n  fexponent_bin: /[pP][+-]?[0-9]+/,\n  deciexp: /\\.[0-9]*@fexponent?/,\n  hexiexp: /\\.[0-9a-zA-Z]*@fexponent_bin?/,\n  irregular_keywords: /val[+-]?|case[+-]?|addr\\@?|fold\\@|free\\@|fix\\@?|lam\\@?|llam\\@?|prop[+-]?|type[+-]?|view[+-@]?|viewt@?ype[+-]?|t@?ype[+-]?|v(iew)?t@?ype[+-]?|abst@?ype|absv(iew)?t@?ype|for\\*?|while\\*?/,\n  ESCHAR: /[ntvbrfa\\\\\\?'\"\\(\\[\\{]/,\n  start: 'root',\n  // The main tokenizer for ATS/Postiats\n  // reference: https://github.com/githwxi/ATS-Postiats/blob/master/src/pats_lexing.dats\n  tokenizer: {\n    root: [// lexing_blankseq0\n    {\n      regex: /[ \\t\\r\\n]+/,\n      action: {\n        token: ''\n      }\n    }, // NOTE: (*) is an invalid ML-like comment!\n    {\n      regex: /\\(\\*\\)/,\n      action: {\n        token: 'invalid'\n      }\n    }, {\n      regex: /\\(\\*/,\n      action: {\n        token: 'comment',\n        next: 'lexing_COMMENT_block_ml'\n      }\n    }, {\n      regex: /\\(/,\n      action: '@brackets'\n      /*{ token: 'delimiter.parenthesis' }*/\n\n    }, {\n      regex: /\\)/,\n      action: '@brackets'\n      /*{ token: 'delimiter.parenthesis' }*/\n\n    }, {\n      regex: /\\[/,\n      action: '@brackets'\n      /*{ token: 'delimiter.bracket' }*/\n\n    }, {\n      regex: /\\]/,\n      action: '@brackets'\n      /*{ token: 'delimiter.bracket' }*/\n\n    }, {\n      regex: /\\{/,\n      action: '@brackets'\n      /*{ token: 'delimiter.brace' }*/\n\n    }, {\n      regex: /\\}/,\n      action: '@brackets'\n      /*{ token: 'delimiter.brace' }*/\n\n    }, // lexing_COMMA\n    {\n      regex: /,\\(/,\n      action: '@brackets'\n      /*{ token: 'delimiter.parenthesis' }*/\n\n    }, {\n      regex: /,/,\n      action: {\n        token: 'delimiter.comma'\n      }\n    }, {\n      regex: /;/,\n      action: {\n        token: 'delimiter.semicolon'\n      }\n    }, // lexing_AT\n    {\n      regex: /@\\(/,\n      action: '@brackets'\n      /* { token: 'delimiter.parenthesis' }*/\n\n    }, {\n      regex: /@\\[/,\n      action: '@brackets'\n      /* { token: 'delimiter.bracket' }*/\n\n    }, {\n      regex: /@\\{/,\n      action: '@brackets'\n      /*{ token: 'delimiter.brace' }*/\n\n    }, // lexing_COLON\n    {\n      regex: /:</,\n      action: {\n        token: 'keyword',\n        next: '@lexing_EFFECT_commaseq0'\n      }\n    },\n    /*\n    lexing_DOT:\n     . // SYMBOLIC => lexing_IDENT_sym\n    . FLOATDOT => lexing_FLOAT_deciexp\n    . DIGIT => T_DOTINT\n    */\n    {\n      regex: /\\.@symbolic+/,\n      action: {\n        token: 'identifier.sym'\n      }\n    }, // FLOATDOT case\n    {\n      regex: /\\.@digit*@fexponent@FLOATSP*/,\n      action: {\n        token: 'number.float'\n      }\n    }, {\n      regex: /\\.@digit+/,\n      action: {\n        token: 'number.float'\n      }\n    }, // lexing_DOLLAR:\n    // '$' IDENTFST IDENTRST* => lexing_IDENT_dlr, _ => lexing_IDENT_sym\n    {\n      regex: /\\$@IDENTFST@IDENTRST*/,\n      action: {\n        cases: {\n          '@keywords_dlr': {\n            token: 'keyword.dlr'\n          },\n          '@default': {\n            token: 'namespace'\n          }\n        }\n      }\n    }, // lexing_SHARP:\n    // '#' IDENTFST IDENTRST* => lexing_ident_srp, _ => lexing_IDENT_sym\n    {\n      regex: /\\#@IDENTFST@IDENTRST*/,\n      action: {\n        cases: {\n          '@keywords_srp': {\n            token: 'keyword.srp'\n          },\n          '@default': {\n            token: 'identifier'\n          }\n        }\n      }\n    }, // lexing_PERCENT:\n    {\n      regex: /%\\(/,\n      action: {\n        token: 'delimiter.parenthesis'\n      }\n    }, {\n      regex: /^%{(#|\\^|\\$)?/,\n      action: {\n        token: 'keyword',\n        next: '@lexing_EXTCODE',\n        nextEmbedded: 'text/javascript'\n      }\n    }, {\n      regex: /^%}/,\n      action: {\n        token: 'keyword'\n      }\n    }, // lexing_QUOTE\n    {\n      regex: /'\\(/,\n      action: {\n        token: 'delimiter.parenthesis'\n      }\n    }, {\n      regex: /'\\[/,\n      action: {\n        token: 'delimiter.bracket'\n      }\n    }, {\n      regex: /'\\{/,\n      action: {\n        token: 'delimiter.brace'\n      }\n    }, [/(')(\\\\@ESCHAR|\\\\[xX]@xdigit+|\\\\@digit+)(')/, ['string', 'string.escape', 'string']], [/'[^\\\\']'/, 'string'], // lexing_DQUOTE\n    [/\"/, 'string.quote', '@lexing_DQUOTE'], // lexing_BQUOTE\n    {\n      regex: /`\\(/,\n      action: '@brackets'\n      /* { token: 'delimiter.parenthesis' }*/\n\n    }, // TODO: otherwise, try lexing_IDENT_sym\n    {\n      regex: /\\\\/,\n      action: {\n        token: 'punctuation'\n      }\n    }, // lexing_IDENT_alp:\n    // NOTE: (?!regex) is syntax for \"not-followed-by\" regex\n    // to resolve ambiguity such as foreach$fwork being incorrectly lexed as [for] [each$fwork]!\n    {\n      regex: /@irregular_keywords(?!@IDENTRST)/,\n      action: {\n        token: 'keyword'\n      }\n    }, {\n      regex: /@IDENTFST@IDENTRST*[<!\\[]?/,\n      action: {\n        cases: {\n          // TODO: dynload and staload should be specially parsed\n          // dynload whitespace+ \"special_string\"\n          // this special string is really:\n          //  '/' '\\\\' '.' => punctuation\n          // ({\\$)([a-zA-Z_][a-zA-Z_0-9]*)(}) => punctuation,keyword,punctuation\n          // [^\"] => identifier/literal\n          '@keywords': {\n            token: 'keyword'\n          },\n          '@keywords_types': {\n            token: 'type'\n          },\n          '@default': {\n            token: 'identifier'\n          }\n        }\n      }\n    }, // lexing_IDENT_sym:\n    {\n      regex: /\\/\\/\\/\\//,\n      action: {\n        token: 'comment',\n        next: '@lexing_COMMENT_rest'\n      }\n    }, {\n      regex: /\\/\\/.*$/,\n      action: {\n        token: 'comment'\n      }\n    }, {\n      regex: /\\/\\*/,\n      action: {\n        token: 'comment',\n        next: '@lexing_COMMENT_block_c'\n      }\n    }, // AS-20160627: specifically for effect annotations\n    {\n      regex: /-<|=</,\n      action: {\n        token: 'keyword',\n        next: '@lexing_EFFECT_commaseq0'\n      }\n    }, {\n      regex: /@symbolic+/,\n      action: {\n        cases: {\n          '@operators': 'keyword',\n          '@default': 'operator'\n        }\n      }\n    }, // lexing_ZERO:\n    // FIXME: this one is quite messy/unfinished yet\n    // TODO: lexing_INT_hex\n    // - testing_hexiexp => lexing_FLOAT_hexiexp\n    // - testing_fexponent_bin => lexing_FLOAT_hexiexp\n    // - testing_intspseq0 => T_INT_hex\n    // lexing_INT_hex:\n    {\n      regex: /0[xX]@xdigit+(@hexiexp|@fexponent_bin)@FLOATSP*/,\n      action: {\n        token: 'number.float'\n      }\n    }, {\n      regex: /0[xX]@xdigit+@INTSP*/,\n      action: {\n        token: 'number.hex'\n      }\n    }, {\n      regex: /0[0-7]+(?![0-9])@INTSP*/,\n      action: {\n        token: 'number.octal'\n      }\n    }, //{regex: /0/, action: { token: 'number' } }, // INTZERO\n    // lexing_INT_dec:\n    // - testing_deciexp => lexing_FLOAT_deciexp\n    // - testing_fexponent => lexing_FLOAT_deciexp\n    // - otherwise => intspseq0 ([0-9]*[lLuU]?)\n    {\n      regex: /@digit+(@fexponent|@deciexp)@FLOATSP*/,\n      action: {\n        token: 'number.float'\n      }\n    }, {\n      regex: /@digit@digitseq0@INTSP*/,\n      action: {\n        token: 'number.decimal'\n      }\n    }, // DIGIT, if followed by digitseq0, is lexing_INT_dec\n    {\n      regex: /@digit+@INTSP*/,\n      action: {\n        token: 'number'\n      }\n    }],\n    lexing_COMMENT_block_ml: [[/[^\\(\\*]+/, 'comment'], [/\\(\\*/, 'comment', '@push'], [/\\(\\*/, 'comment.invalid'], [/\\*\\)/, 'comment', '@pop'], [/\\*/, 'comment']],\n    lexing_COMMENT_block_c: [[/[^\\/*]+/, 'comment'], // [/\\/\\*/, 'comment', '@push' ],    // nested C-style block comments not allowed\n    // [/\\/\\*/,    'comment.invalid' ],\t// NOTE: this breaks block comments in the shape of /* //*/\n    [/\\*\\//, 'comment', '@pop'], [/[\\/*]/, 'comment']],\n    lexing_COMMENT_rest: [[/$/, 'comment', '@pop'], [/.*/, 'comment']],\n    // NOTE: added by AS, specifically for highlighting\n    lexing_EFFECT_commaseq0: [{\n      regex: /@IDENTFST@IDENTRST+|@digit+/,\n      action: {\n        cases: {\n          '@keywords_effects': {\n            token: 'type.effect'\n          },\n          '@default': {\n            token: 'identifier'\n          }\n        }\n      }\n    }, {\n      regex: /,/,\n      action: {\n        token: 'punctuation'\n      }\n    }, {\n      regex: />/,\n      action: {\n        token: '@rematch',\n        next: '@pop'\n      }\n    }],\n    lexing_EXTCODE: [{\n      regex: /^%}/,\n      action: {\n        token: '@rematch',\n        next: '@pop',\n        nextEmbedded: '@pop'\n      }\n    }, {\n      regex: /[^%]+/,\n      action: ''\n    }],\n    lexing_DQUOTE: [{\n      regex: /\"/,\n      action: {\n        token: 'string.quote',\n        next: '@pop'\n      }\n    }, // AS-20160628: additional hi-lighting for variables in staload/dynload strings\n    {\n      regex: /(\\{\\$)(@IDENTFST@IDENTRST*)(\\})/,\n      action: [{\n        token: 'string.escape'\n      }, {\n        token: 'identifier'\n      }, {\n        token: 'string.escape'\n      }]\n    }, {\n      regex: /\\\\$/,\n      action: {\n        token: 'string.escape'\n      }\n    }, {\n      regex: /\\\\(@ESCHAR|[xX]@xdigit+|@digit+)/,\n      action: {\n        token: 'string.escape'\n      }\n    }, {\n      regex: /[^\\\\\"]+/,\n      action: {\n        token: 'string'\n      }\n    }]\n  }\n};","map":null,"metadata":{},"sourceType":"module"}